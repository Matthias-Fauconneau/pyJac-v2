/*

A cog-templated skeleton for pyJac kernel execution

OpenCL code adapted from:
    Based on https://www.olcf.ornl.gov/tutorials/opencl-vector-addition/
    and https://www.fixstars.com/en/opencl/book/OpenCLProgrammingBook/calling-the-kernel/

(C) Nicholas Curtis - 2018

Global declarations for Cog:
    - codegen: path to a serialized CallgenResult instance
    that may be loaded to generate this file
*/

#ifndef KERNEL_H
#define KERNEL_H

/*[[[cog
    import six
    from textwrap import dedent
    from six.moves import cPickle as pickle
    import loopy as lp
    from pyjac.utils import indent, stdindent
    from pyjac.kernel_utils.memory_tools import get_memory, HostNamer, DeviceNamer
    from pyjac.kernel_utils.tools import get_kernel_args, get_temporaries, get_include, \
        make_doc_str
    from pyjac.utils import enum_to_string, can_vectorize_lang

    # load serialized callgen
    with open(callgen, 'rb') as file:
        callgen = pickle.load(file)

    # and create memory tools
    mem = get_memory(callgen, host_namer=HostNamer(), device_namer=DeviceNamer())

    # headers
    headers = ['mechanism', 'error_check', 'timer']
    wrappers = {}
    if can_vectorize_lang[callgen.lang]:
        headers.append('vectorization')
    if callgen.lang != 'opencl':
        # include driver header
        headers.append('{}_driver'.format(callgen.name))
        wrappers[headers[-1]] = dedent(
        """
            {include}
            // undefine work size in main to avoid name collisions
            #undef work_size
        """).strip()

    for header in headers:
        include = get_include(callgen, header)
        if header in wrappers:
            include = wrappers[header].format(include=include)
        cog.outl(include)

  ]]]
  [[[end]]]*/


#include <stdlib.h>
#include <stdio.h>
#include <string.h>
#include <stdbool.h>
#include <sstream.h>
/*[[[cog
    if callgen.lang == 'opencl':
        cog.outl("""
    extern "C" {
        #include <CL/cl.h>
    }

    #define NUM_PLATFORMS (16)
    #define MAX_DEVICE (16)

    // macro definitions
    """, trimblanklines = True, dedent=True)
        cog.outl('#define CL_LEVEL {}'.format(callgen.cl_level))
        cog.outl('#define {}'.format(enum_to_string(callgen.dev_mem_type).upper()))
  ]]]
  [[[end]]]*/


//! \brief The base kernel class
class Kernel
{

public:
    Kernel();
    ~Kernel();
    /*[[[cog
         cog.outl(make_doc_str(callgen, ['problem_size', 'work_size',
                                         'do_not_compile'],
                  'Resize kernel\'s working data to fit the given sizes.'))
      ]]]
      [[[end]]]*/
    void resize(size_t problem_size, size_t work_size, bool do_not_compile=false);
    void finalize();

    //! \brief Returns the ordered list of species names in the chemical model
    static const std::vector<std::string>& speciesNames()
    {
        return _species_names;
    }

    /** \brief Returns the list of reaction strings in the chemical model

        \note Currently only implemented for pyJac codes generated using Cantera
              mechanisms.  If this file has been generated using a Chemkin mechanism
              this function will return an empty vector.
     */
    static const std::vector<std::string>& reactionStrings()
    {
        return _rxn_strings;
    }

    //! \brief Return the data-ordering used in this kernel, either 'C' (row-major)
    //!        or 'F' (column-major)
    static const std::string& order()
    {
        return _order;
    }

    /*[[[cog
         if can_vectorize_lang[lang]:
            cog.outl("""
            //! \brief Return the vector-width used by this kernel
            static const unsigned int vectorWidth()
            {
                return _vector_width;
            }""", dedent=True, trimblanklines=True)
      ]]]
      [[[end]]]*/

    /** \brief Returns the total amount of working memory required per-thermochemical
      *        state for this kernel, in bytes.
      *
      * \note  This includes vectorization considerations.
      */
    virtual const std::size_t requiredMemorySize() const = 0;

    /*[[[cog
         if callgen.lang == 'opencl':
            # output compiler
            cog.outl('virtual void compile() = 0;')
            cog.outl("""
            // info variables -- common to all kernels

            //! \brief Return the OpenCL build options used in kernel compilation
            static const std::string& buildOptions() { return Kernel::build_options; }
            //! \brief Return the name of the OpenCL platform used for kernel execution
            static const std::string& platform() { return Kernel::platform; };
            //! \brief return the type of OpenCL device used for kernel execution
            static const unsigned int deviceType() { return Kernel::device_type; }
            """, trimblanklines=True, dedent=True)

         elif callgen.lang == 'c':
            cog.outl('void compile(){}')
            cog.outl('void threadset(unsigned int num_threads);')
      ]]]
      [[[end]]]*/

protected:
    size_t per_run();
    size_t per_run(size_t problem_size);
    size_t this_run(size_t offset);

    /*[[[cog
        if callgen.lang == 'opencl':
            cog.outl("""
            // opencl context, kernel, etc.
            cl_kernel kernel;
            cl_program program;
            cl_context context;
            cl_command_queue queue;
            // info variables -- specified per kernel
            unsigned int num_source;
            const char* kernel_path;
            """, trimblanklines=True, dedent=True)

            # write build options / platform / device dtype
            cog.outl('static constexpr char* build_options = "{}";'.format(
                callgen.build_options))
            cog.outl('static constexpr char* platform_check = "{}";'.format(
                callgen.build_options))
            try:
                device_type = int(callgen.device_type)
            except ValueError:
                assert isinstance(callgen.device_type, str)
                device_type = callgen.device_type
            cog.outl('static constexpr unsigned int device_type = {};'.format(
                device_type))

      ]]]
      [[[end]]]*/

    // flags indicating initialization status, etc.
    bool initialized;
    bool compiled;

    // past run sizes
    size_t d_per_run; // store for device per-run size
    size_t problem_size;
    size_t max_per_run;
    size_t work_size;

    // info variables

    // species names
    //[[[cog cog.outl('static constexpr std::vector<std::string> _species_names = '
    //                '{{ {} }};').format(stringify_args(callgen.species_names)))]]]
    //[[[end]]]
    // reaction strings
    //[[[cog cog.outl('static constexpr std::vector<std::string> _rxn_strings = '
    //                '{{ {} }};').format(stringify_args(callgen.rxn_strings)))]]]
    //[[[end]]]
    // data order
    //[[[cog cog.outl('static constexpr std::string _order = "{}"'.format(
    //                 callgen.order)]]]
    //[[[end]]]
    /*[[[cog
         if can_vectorize_lang[lang]:
            cog.outl("""
            // vector width
            //! \brief Return the vector-width used by this kernel
            static constexpr unsigned int _vector_width = {};
            """.format(callgen.local_size, dedent=True, trimblanklines=True)
      ]]]
      [[[end]]]*/


    /*[[[cog
        cog.outl(
            make_doc_str(callgen, ['problem_size', 'work_size'],
                         'Create the {} kernel.'.format(
                            callgen.lang.title())))
      ]]]
      [[[end]]]*/
    void init(size_t problem_size, size_t work_size);

    // memory initialization / release accomplished in sub-classes
    virtual void mem_init(size_t problem_size, size_t work_size) = 0;
    virtual void finalize_memory() = 0;
};

// and subclass(es)
/*[[[cog
for kernel, args in six.iteritems(callgen.kernel_args):
    cog.out("""
class {kernel_name}Kernel : public Kernel
{{
protected:
    // declare device buffers
""".format(kernel_name=kernel.title()), dedent=True, trimblanklines=True)

    # define kernel args
    for arg in callgen.kernel_data[kernel]:
        if not (isinstance(arg, lp.ValueArg) or
                arg.address_space == lp.AddressSpace.LOCAL):
            cog.outl(indent(mem.define(True, arg), stdindent))
    cog.out("""
    #ifdef PINNED
        // declare temporary pointers to hold mapped addresses
    """,  dedent=True, trimblanklines=True)
    # define temps
    for temp in get_temporaries(mem, callgen.kernel_data[kernel]):
        cog.outl(indent(temp, stdindent))
    cog.out("""
    #endif
    """,  dedent=True, trimblanklines=True)

    # overrides
    cog.outl(indent('void mem_init(size_t problem_size, size_t work_size);', stdindent))

    cog.outl('public:')
    if callgen.lang == 'opencl':
        cog.out('void compile();')

    # write constructor
    cog.out("""
    /*
    Base constructor -- no arguments necessary, for use with Cython.
    {name}Kernel::resize() must be called before use.
    */
    {name}Kernel();
    """.format(name=kernel.title()), dedent=False, trimblanklines=True)

    # write alternate constructor that allows memory initialization
    cog.out(make_doc_str(
        callgen, ['problem_size', 'work_size', 'do_not_compile'],
        'Initializing constructor.'))
    cog.out("""
    {name}Kernel(size_t problem_size, size_t work_size, bool do_not_compile=false);
    """.format(name=kernel.title()), dedent=False, trimblanklines=True)

    cog.out(make_doc_str(
        callgen, callgen.kernel_args[kernel],
        "Execute the {} kernel '{}'".format(callgen.lang.title(), kernel)))
    cog.out("""
    void operator()({knl_args});
    """.format(knl_args=get_kernel_args(mem, callgen.kernel_args[kernel])), dedent=False, trimblanklines=True)

    # overrides
    cog.outl(indent('void finalize_memory();', stdindent))
]]]
[[[end]]]*/
};


#endif

/*
OpenCL_kernel.cpp

A cog-templated skeleton for pyJac opencl kernel execution

Based on https://www.olcf.ornl.gov/tutorials/opencl-vector-addition/
and https://www.fixstars.com/en/opencl/book/OpenCLProgrammingBook/calling-the-kernel/

Nicholas Curtis - 2017

Global declarations for Cog:
    - codegen: path to a serialized CallgenResult instance
    that may be loaded to generate this file
*/

/*[[[cog
    import loopy as lp
    import numpy as np
    import re
    from textwrap import indent
    from six.moves import cPickle as pickle
    from string import Template
    with open(callgen, 'rb') as file:
        callgen = pickle.load(file)
    num_source = len(callgen.source_names)

    from pyjac.kernel_utils.memory_tools import get_memory, HostNamer, DeviceNamer
    mem = get_memory(callgen, host_namer=HostNamer(), device_namer=DeviceNamer())
]]]
[[[end]]]*/

//[[[cog cog.outl('#include "{}_main.oclh"'.format(callgen.name))]]]
//[[[end]]]
#include "read_initial_conditions.oclh"
#include "write_data.oclh"
#include "memcpy_2d.oclh"

// macro definitions
/*[[[cog
    from pyjac.utils import enum_to_string
    cog.outl('#define CL_LEVEL {}'.format(callgen.cl_level))
    cog.outl('#define {}'.format(enum_to_string(callgen.dev_mem_type).upper()))
  ]]]
  [[[end]]]*/

class Kernel
{

public:
    Kernel() : init(false)
    {

    }

    ~Kernel()
    {
        this->finalize();
    }

    // execute the kernel, defined in the subclasses
    virtual void operator()(size_t problem_size, size_t work_groups) = 0;

protected:
    // opencl context, kerne, etc.
    cl_kernel kernel;
    cl_program program;
    cl_context context;
    cl_command_queue queue;

    // flag indicating initialization status
    bool init;

    // past run sizes
    size_t per_run_store;
    size_t max_per_run;

    // info variables -- specified per kernel
    unsigned int num_source;
    char** kernel_paths;

    // info variables -- common to all kernels
    /*[[[cog
    cog.outl('char* build_options = "{}";'.format(callgen.build_options))
    cog.outl('char* platform_check = "{}";'.format(callgen.platform))
    cog.outl('unsigned int device_type = {};'.format(int(callgen.device_type)));
    ]]]
    [[[end]]]

    /*
    Create opencl kernel

    Parameters
    ----------
    size_t per_run: size_t
        The number of initial conditions to execute per-run, due to memory limits.
        May be >= problem_size
    problem_size : size_t
        The number of initial conditions to execute in total
    work_size : uint
        The number of OpenCL groups to launch.
        If using GPUs, this is the # of CUDA blocks to use
        If for CPUs, this is the number of logical cores to use
    */
    void init(size_t per_run, size_t problem_size, cl_uint work_size)
    {
        cl_platform_id platform_id[NUM_PLATFORMS];
        cl_device_id device_ids[MAX_DEVICE];
        cl_uint ret_num_platforms;
        cl_uint ret_num_devices;
        cl_uint num_cores;
        cl_uint num_devices = 1;
        cl_int return_code;

        size_t* source_sizes = (size_t*)malloc(this->num_source * sizeof(size_t));
        unsigned char** source_bins = (unsigned char**)malloc(this->num_source * sizeof(unsigned char*));

        cl_device_type device_type = this->device_type
        FILE *fp;

        for (int i = 0; i < this->num_source; ++i)
        {
            /* Load kernel source code */
            fp = fopen(this->kernel_paths[i], "rb");
            if (!fp) {
                exit(-1);
            }
            //find file size
            fseek(fp, 0L, SEEK_END);
            source_sizes[i] = ftell(fp);
            rewind(fp);

            //read file
            source_bins[i] = (unsigned char*)malloc(source_sizes[i]);
            cassert(fread(source_bins[i], 1, source_sizes[i], fp) == source_sizes[i], "Error reading source binary...");
            fclose(fp);
        }

        /* Get platform/device information */
        check_err(clGetPlatformIDs(NUM_PLATFORMS, platform_id, &ret_num_platforms));
        cl_platform_id pid = NULL;
        for (int i = 0; i < ret_num_platforms; ++i)
        {
            //check if matches user-supplied platform
            char pvendor[100];
            size_t psize = 100 * sizeof(char);
            check_err(clGetPlatformInfo(platform_id[i], CL_PLATFORM_VENDOR, psize, pvendor, NULL));
            if(strstr(pvendor, platform_check) != NULL)
            {
                pid = platform_id[i];
                break;
            }
        }
        cassert(pid != NULL, "Platform not found");

        if (device_type != CL_DEVICE_TYPE_GPU)
        {
            //we're going to create a subdevice limited to work_size # of cores
            //all systems tested show multi-cpus as a single device.
            num_devices = 1;
        }
        else if (num_devices >= MAX_DEVICE)
        {
            fprintf(stderr, "Cannot create program with %d devices, please update MAX_DEVICE definition.\n", num_devices);
            exit(EXIT_FAILURE);
        }

        //get the device to compile for
        check_err(clGetDeviceIDs(pid, device_type, num_devices, device_ids, &ret_num_devices));

        cassert(ret_num_devices > 0, "No devices found!");

        //now we need to create subdevices for the CPU
        if (device_type == CL_DEVICE_TYPE_CPU)
        {
            cl_uint num_compute;
            //first get the maximum number of sub partitions (i.e. logical threads)
            check_err(clGetDeviceInfo(device_ids[0], CL_DEVICE_MAX_COMPUTE_UNITS, sizeof(num_compute), &num_compute, NULL));
            cassert(work_size <= num_compute, "Too many cores used...");

            //ok, now we know we're ok
            //let's create a subdevice with the required number of compute units
            // Partition properties
            cl_device_partition_property properties[3];
            // Partition type
            properties[0] = CL_DEVICE_PARTITION_BY_COUNTS;
            // number of compute units
            properties[1] = work_size;
            // List end
            properties[2] = CL_DEVICE_PARTITION_BY_COUNTS_LIST_END;

            // Specifies the size of the out_devices array
            cl_uint num_sub_devices = 1;
            // Provides a buffer for the generated subdevices with a number of elements specified by num_sub_devices
            cl_device_id sub_device_ids;
            // Create the subdevices for the device_id device
            check_err(clCreateSubDevices(device_ids[0], properties, num_sub_devices, &sub_device_ids, &ret_num_devices));
            cassert(ret_num_devices > 0, "No sub-devices could be created!");
            //and assign to the device_ids
            device_ids[0] = sub_device_ids;
            num_devices = num_sub_devices;
        }

        //for the moment, limit to one device
        cassert(num_devices == 1, "Currently limited to a single device");

        //create context
        this->context = clCreateContext(NULL, num_devices, &device_ids[0], NULL, NULL, &return_code);
        check_err(return_code);

        //create queue
        this->queue = clCreateCommandQueue(this->context, device_ids[0], 0, &return_code);
        check_err(return_code);

        /* Create Kernel program from the read in source binary */
        cl_int bin_status;
        this->program = clCreateProgramWithBinary(context, num_devices, &device_ids[0], source_sizes, (const unsigned char**)source_bins, &bin_status, &return_code);
        check_err(bin_status);
        check_err(return_code);

        /* Build Program */
        return_code = clBuildProgram(this->program, num_devices, &device_ids[0], this->build_options, NULL, NULL);
        if (return_code != CL_SUCCESS)
        {
              fprintf(stderr, "OpenCL failed to build the program...\n");

              size_t len;
              char *buffer;
              check_err(clGetProgramBuildInfo(this->program, device_ids[0], CL_PROGRAM_BUILD_LOG, sizeof(char*), NULL, &len));
              buffer = calloc(len, sizeof(char));
              check_err(clGetProgramBuildInfo(this->program, device_ids[0], CL_PROGRAM_BUILD_LOG, len * sizeof(char), buffer, NULL));
              fprintf(stderr, "%s\n", buffer);
              free(buffer);

              clGetProgramBuildInfo(this->program, device_ids[0], CL_PROGRAM_BUILD_STATUS, sizeof(char*), NULL, &len);
              buffer = calloc(len, sizeof(char));
              clGetProgramBuildInfo(this->program, device_ids[0], CL_PROGRAM_BUILD_STATUS, len * sizeof(char), buffer, NULL);
              fprintf(stderr, "%s\n", buffer);
              free(buffer);

              check_err(return_code);
        }

        for(int i = 0; i < this->num_source; ++i)
        {
            free(source_bins[i]);
        }
        free(source_bins);
        free(source_sizes);

        this->mem_init(per_run, problem_size, work_size);
        // mark initialized
        this->init = true;
    }

    // memory initialization / release accomplished in sub-classes
    virtual void mem_init(size_t per_run, size_t problem_size, size_t work_size) = 0;
    virtual void finalize_memory() = 0;

    void finalize()
    {
        this->finalize_memory();
        check_err(clReleaseProgram(this->program));
        check_err(clReleaseCommandQueue(this->queue));
        check_err(clReleaseContext(this->context));
        // mark deinit
        this->init = false;
    }
}


    /*[[[cog
# generate sub-kernel classes
for kernel in callgen.kernel_args:
    # create a new memory manager to get 'this->' for device buffers
    kmem = get_memory(callgen, host_namer=HostNamer(),
                      device_namer=DeviceNamer('this'))

    cog.out("""
class {kernel_name}Kernel : protected Kernel
{{
protected:
    // declare device buffers
    """.format(kernel_name=kernel.title()), dedent=True, trimblanklines=True)

    # always have a double-precision temp
    temps = [lp.GlobalArg('temp_d', dtype=np.float64)]
    if any([x.dtype.is_integral() and isinstance(x, lp.ArrayArg)
            for x in callgen.kernel_args[kernel]]):
        # need integer temporary
        arr = next(x for x in callgen.kernel_args[kernel] if x.dtype.is_integral())
        temps.append(lp.GlobalArg('temp_i', dtype=arr.dtype))

    # define kernel args
    from pyjac.utils import indent as stdindent
    for arg in callgen.kernel_args[kernel]:
        cog.outl(indent(mem.define(True, arg), stdindent))
    cog.out("""
    #ifdef PINNED
        // declare temporary pointers to hold mapped addresses
    """,  dedent=True, trimblanklines=True)
    # define temps
    for arg in temps:
        cog.outl(indent(mem.define(False, arg), stdindent))

    cog.out("""
    #endif

    /*
    Initialize memory & assign kernel args for the kernel

    Parameters
    ----------
    per_run : size_t
        The number of conditions to execute per run, the problem_size will be broken
        into chunks if it exceeds the per_run size
    problem_size : size_t
        The total number of conditions to execute this kernel over
    work_size : size_t
        The number of OpenCL groups to launch.
        If using GPUs, this is the # of CUDA blocks to use
        If for CPUs, this is the number of logical cores to use
    */
    void mem_init(size_t per_run, size_t problem_size, size_t work_size)
    {
        #if CL_LEVEL >= 120
            // with CL 1.2, we have access to clEnqueueFillBuffer
            double zero = 0;
        #else
            // otherwise, we need a zero buffer to use clEnqueueWriteBuffer
    """, dedent=True, trimblanklines=True)
    # determine maximum size
    max_size = [mem.non_ic_size(arr) for arr in callgen.kernel_args[kernel]
                if not isinstance(arr, lp.ValueArg)]
    from pyjac.utils import partition, is_integer
    problem_sizes, work_sizes = partition(max_size, is_integer)
    problem_size = '{} * problem_size'.format(max([int(x) for x in problem_sizes]))
    # make sure work sizes are what we expect
    regex = re.compile(r'work_size\s*\*\s*(\d+)')
    assert all(regex.search(x) for x in work_sizes)
    # next, extract the work sizes
    work_size = '{} * work_size'.format(
        max([int(regex.search(x).group(1)) for x in work_sizes]))
    max_size = '({0} > {1} ? {0} : {1})'.format(problem_size, work_size)

    cog.out("""
            double* zero = (double*)malloc({max_size} * sizeof(double));
            memset(zero, 0, {max_size} * sizeof(double));
        #endif

        /* If we've run out of constant memory space, we will place converted
           global constant here */

    """.format(max_size=max_size), dedent=False, trimblanklines=True)
    for arr in callgen.host_constants[kernel]:
        # define
        cog.outl("""
        {}
        """.format(kmem.define(False, arr, host_constant=True)),
                 dedent=True, trimblanklines=True)

    cog.out("""
    cl_int return_code;
    /* Alloc buffers */
    """, dedent=False, trimblanklines=True)

    for arr in callgen.kernel_args[kernel]:
        if not isinstance(arr, lp.ValueArg):
            cog.outl(indent(kmem.alloc(True, arr), stdindent))

    cog.out("""
    /* we transfer the constants here, as we only need to do so once */
    """, dedent=False, trimblanklines=True)
    for arr in callgen.host_constants[kernel]:
        cog.outl(indent(kmem.copy(True, arr, host_constant=True), stdindent))

    # and create kernel
    cog.outl("""
    #if CL_LEVEL < 120
        free(zero);
    #endif

    /* Create OpenCL Kernel */
    this->kernel = clCreateKernel(program, "{knl_name}", &return_code);
    check_err(return_code);

    /* Kernel arg setting */
    """.format(knl_name=kernel), dedent=False, trimblanklines=True)
    # finally set kernel args
    set_arg = ('check_err(clSetKernelArg(kernel, {arg_index}, '
               '{arg_size}, {arg_value}));')

    for i, arg in enumerate(callgen.kernel_args[kernel]):
        if not isinstance(arg, lp.ValueArg):
            cog.outl(
                indent(set_arg.format(
                    arg_index=i,
                    arg_size='sizeof({})'.format(kmem.dtype(True, arg)),
                    arg_value='&' + kmem.get_name(True, arg.name)),
                    stdindent))
        else:
            # workaround for integer overflow of cl_uint
            # switch problem-size -> per-run, as that is what the device sees
            name_maps = {'problem_size': 'per_run'}
            name = arg.name if arg.name not in name_maps else \
                name_maps[arg.name]
            arg_set = set_arg.format(
                    arg_index=i,
                    arg_size='sizeof({})'.format(kmem.dtype(True, arg)),
                    arg_value='&{}'.format(kmem.get_name(True, name)))
            cog.outl(indent(arg_set, stdindent))

    cog.outl('}')

    # memory free's
    cog.out("""
void finalize_memory()
{
    """, dedent=False, trimblanklines=True)
    for arr in callgen.kernel_args[kernel]:
        cog.outl(indent(kmem.free(True, arr), stdindent))
    cog.outl("""
}

    public:
    """, trimblanklines=True)

    # write constructor
    cog.out("""
    {name}Kernel():
    """.format(name=kernel.title()), dedent=True, trimblanklines=True)
    cog.outl(indent('num_source({}),'.format(len(callgen.source_names)), stdindent))
    cog.outl(indent('kernel_paths({', stdindent))
    files = callgen.source_names
    for i, file in enumerate(files):
        cog.outl(indent("\"{}\"{}{}".format(
        file, ',' if i < len(files) - 1 else '',
        '})' if i == len(files) - 1 else ''), stdindent))
    cog.out("""
    {

    }
    """, dedent=False, trimblanklines=True)

    # write kernel docs
    cog.out("""

    /*
    Execute the OpenCL kernel '{}'

    Parameters
    ----------
    problem_size : size_t
        The number of initial conditions to evaluate
    work_groups: size_t
        On a CPU, this corresponds to the number of cores to run on,
        while on a GPU this represents the total number of OpenCL work-groups
        (a.k.a., Blocks in CUDA terminology) to run.
    """.format(kernel), dedent=True, trimblanklines=True)

    def __get_docs(arg):
        if arg.name in callgen.docs:
            return callgen.docs[arg.name]
        else:
            return ('???', 'Unknown kernel argument {}.'.format(arg.name))

    # generate docs
    for arg in callgen.kernel_args[kernel]:
        cog.outl("""
    {} : {}
        {}""".format(arg.name, *__get_docs(arg)), dedent=True, trimblanklines=True)
    cog.outl('*/')

    # write kernel defn
    cog.out("""
void operator()(size_t problem_size, size_t work_groups)
{{
    """.format(name=kernel, knl_args=', '.join([
            mem.get_name(False, arr) for arr in callgen.kernel_args[kernel]])),
            dedent=False, trimblanklines=True)

    cog.out("""
        // error checking for pinned memory transfers
        cl_int return_code;
        size_t per_run = this->max_per_run < problem_size ? this->max_per_run : problem_size;

        for (size_t offset = 0; offset < problem_size; offset += per_run)
        {{
            size_t this_run = problem_size - offset < per_run ? problem_size - offset : per_run;
            size_t global_work_size = work_groups;
            size_t local_work_size = {local_size};
            #if defined(DEEP) && !defined(EXPLICIT_SIMD)
                // need to multiply global worksize by local worksize
                // to get correct number of global items (as)
                global_work_size *= local_work_size;
            #endif
            // Memory Transfers into the kernel, if any
        """.format(local_size=callgen.local_size), dedent=False, trimblanklines=True)

    # write memory transfers in
    for arg in callgen.kernel_args[kernel]:
        if not isinstance(arg, lp.ValueArg):
            cog.outl(indent(kmem.copy(to_device=True, arr=arg), stdindent * 3))

    # call kernel
    cog.outl("""
            // run kernel
            check_err(clEnqueueNDRangeKernel(queue, this->kernel, 1, NULL, &global_work_size, &local_work_size, 0, NULL, NULL));
            // Memory Transfers out
            """, dedent=False, trimblanklines=True)

    # and finally write memory transfers out
    for arg in callgen.kernel_args[kernel]:
        if not isinstance(arg, lp.ValueArg):
            cog.outl(indent(kmem.copy(to_device=False, arr=arg), stdindent * 3))

    # and close
    cog.out("""
        }
    }
    """, dedent=False, trimblanklines=True)
]]]
[[[end]]]*/


int main(int argc, char* argv[])
{

    //check args
    cassert(argc >= 3, "Missing arguments...");

    //arglist is:
    //#0 - the program name
    //#1 - the problem size
    //#2 - the number of cores [CPU/Accelerator] or number GPU blocks [GPU only]
    //#3 - whether to compile

    size_t problem_size = atoi(argv[1]);
    cl_uint work_size = atoi(argv[2]);
    int compile = 1;
    if (argc >= 4)
        compile = atoi(argv[3]);

    //first compile to binary
    double compilation_time = -1;
    if (compile)
    {
        StartTimer();
        compiler();
        compilation_time = GetTimer();
    }

    ${local_allocs}

    //init memory & program
    StartTimer();
    size_t per_run = max_per_run < problem_size ? max_per_run : problem_size;
    init(per_run, problem_size, work_size);
    double setup_time = GetTimer();
    //read input data
    read_initial_conditions("${data_filename}", problem_size,
                                ${read_args},
                                '${order}');

    StartTimer();
    execute_kernel(problem_size, ${local_input_args});
    double runtime = GetTimer();

    printf("%zu,%.15le,%.15le,%.15le\n", problem_size, compilation_time,
                setup_time, runtime);

    // write output to file if supplied
    char* output_files[${num_outputs}] = {${output_paths}};
    size_t output_sizes[${num_outputs}] = {${output_sizes}};
    double* outputs[${num_outputs}] = {${outputs}};
    for(int i = 0; i < ${num_outputs}; ++i)
    {
        write_data(output_files[i], outputs[i], output_sizes[i]);
    }

    finalize();

    ${local_frees}

    return 0;
}
